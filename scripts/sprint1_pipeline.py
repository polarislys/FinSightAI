"""
Sprint 1: æœ€å°åŒ– RAG é—­ç¯
ä¸Šä¼ æ–‡æ¡£ -> å­˜å…¥åº“ -> æé—® -> å›ç­”
"""
import sys
sys.path.append('.')

from src.data_loader.pdf_parser_api import PDFParserAPI  # æ”¹ç”¨ API ç‰ˆæœ¬
from src.data_loader.text_splitter import FinancialTextSplitter
from src.retrieval.milvus_client import MilvusClient
from pathlib import Path
import logging
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
# è®¾ç½® Hugging Face ç¼“å­˜ï¼ˆåœ¨åˆå§‹åŒ–æ¨¡å‹ä¹‹å‰ï¼‰
os.environ['HF_HOME'] = os.getenv('HF_HOME', '/home/nl/disk_8T/lys/cache/huggingface')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Sprint1Pipeline:
    """ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ RAG ç®¡é“"""
    
    def __init__(self):
        self.pdf_parser = PDFParserAPI("./data/processed")  # ä½¿ç”¨ API è§£æå™¨
        self.text_splitter = FinancialTextSplitter(chunk_size=512)
        self.milvus = MilvusClient("./data/milvus_lite.db")
        
        # SiliconFlow (Qwen 7B)
        self.llm = OpenAI(
            api_key=os.getenv("SILICONFLOW_API_KEY"),
            base_url="https://api.siliconflow.cn/v1"
        )
        logger.info("âœ… åˆå§‹åŒ–å®Œæˆ")
    
    def ingest_pdfs(self, pdf_dir: str):
        """æ•°æ®æ‘„å–ï¼šPDFè§£æ + åˆ‡åˆ† + å…¥åº“"""
        logger.info(f"\n{'='*60}")
        logger.info("ï¿½ Step 1: PDF è§£æï¼ˆMinerUï¼‰")
        logger.info(f"{'='*60}")
        
        # 1. è§£æPDF
        parsed_results = self.pdf_parser.batch_parse(pdf_dir)
        
        if not parsed_results:
            logger.error("âŒ æ²¡æœ‰æˆåŠŸè§£æçš„PDF")
            return
        
        # 2. è¯»å–Markdownå¹¶åˆ‡åˆ†
        logger.info(f"\n{'='*60}")
        logger.info("âœ‚ï¸  Step 2: æ–‡æœ¬åˆ‡åˆ†ï¼ˆTokenTextSplitterï¼‰")
        logger.info(f"{'='*60}")
        
        all_chunks = []
        for result in parsed_results:
            md_path = result['markdown']  # ä»å­—å…¸ä¸­è·å– markdown æ–‡ä»¶è·¯å¾„
            with open(md_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            chunks = self.text_splitter.split_text(text)
            for i, chunk in enumerate(chunks):
                all_chunks.append({
                    'text': chunk,
                    'metadata': {'source': Path(md_path).name},
                    'chunk_id': i
                })
        
        # 3. å‘é‡åŒ–å¹¶å…¥åº“
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ”¢ Step 3: å‘é‡åŒ–å…¥åº“ï¼ˆBGE-M3 + Milvusï¼‰")
        logger.info(f"{'='*60}")
        
        self.milvus.insert(all_chunks)
        
        logger.info(f"\nâœ… æ•°æ®æ‘„å–å®Œæˆï¼")
        logger.info(f"   - è§£æPDF: {len(parsed_results)} ä¸ª")
        logger.info(f"   - ç”Ÿæˆchunks: {len(all_chunks)} ä¸ª")
    
    def query(self, question: str) -> str:
        """æœ´ç´  RAG æŸ¥è¯¢"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ” ç”¨æˆ·æé—®: {question}")
        logger.info(f"{'='*60}")
        
        # 1. å‘é‡æ£€ç´¢
        results = self.milvus.search(question, top_k=3)
        
        logger.info(f"\nğŸ“Š æ£€ç´¢ç»“æœ:")
        for i, res in enumerate(results, 1):
            logger.info(f"{i}. [ç›¸ä¼¼åº¦: {res['score']:.3f}] {res['source']}")
            logger.info(f"   {res['text'][:80]}...\n")
        
        # 2. æ„å»º Prompt
        context = "\n\n".join([r['text'] for r in results])
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æåŠ©æ‰‹ã€‚æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

ã€è¦æ±‚ã€‘
1. ä»…åŸºäºå‚è€ƒèµ„æ–™å›ç­”
2. å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜
3. å›ç­”è¦ç®€æ´ä¸“ä¸š

ã€å›ç­”ã€‘"""
        
        # 3. è°ƒç”¨ Qwen 7B
        logger.info("ğŸ’¬ è°ƒç”¨ SiliconFlow (Qwen 7B)...")
        response = self.llm.chat.completions.create(
            model="Qwen/Qwen2.5-7B-Instruct",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=512
        )
        
        answer = response.choices[0].message.content
        
        logger.info(f"\nğŸ¤– AI å›ç­”:\n{answer}\n")
        return answer


def main():
    import argparse
    parser = argparse.ArgumentParser(description='Sprint 1: æœ€å°åŒ–RAGé—­ç¯')
    parser.add_argument('--ingest', action='store_true', help='æ•°æ®æ‘„å–')
    parser.add_argument('--query', type=str, help='æŸ¥è¯¢é—®é¢˜')
    args = parser.parse_args()
    
    pipeline = Sprint1Pipeline()
    
    if args.ingest:
        pipeline.ingest_pdfs("./data/raw_pdfs/research_reports")
    
    if args.query:
        pipeline.query(args.query)
    
    # äº¤äº’æ¨¡å¼
    if not args.ingest and not args.query:
        print("\nğŸ’¬ è¿›å…¥äº¤äº’æ¨¡å¼ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰\n")
        while True:
            question = input("ğŸ™‹ ä½ çš„é—®é¢˜: ").strip()
            if question.lower() in ['quit', 'exit', 'q']:
                break
            if question:
                pipeline.query(question)


if __name__ == "__main__":
    main()