import os
from dotenv import load_dotenv

load_dotenv()

print("ğŸ” æµ‹è¯• OpenAI å¯¼å…¥...")

try:
    from openai import OpenAI
    print("âœ… OpenAI å¯¼å…¥æˆåŠŸ")
    
    print("ğŸ” æµ‹è¯• OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–...")
    client = OpenAI(
        api_key=os.getenv("SILICONFLOW_API_KEY"),
        base_url=os.getenv("SILICONFLOW_BASE_URL")
    )
    print("âœ… OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    
    print("ğŸ” æµ‹è¯•ç®€å• API è°ƒç”¨...")
    response = client.chat.completions.create(
        model=os.getenv("LLM_MODEL"),
        messages=[{"role": "user", "content": "ä½ å¥½"}],
        max_tokens=10
    )
    print("âœ… API è°ƒç”¨æˆåŠŸ")
    print(f"å›å¤: {response.choices[0].message.content}")
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()