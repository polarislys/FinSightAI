### 1. 基础设施与技术栈 (Infrastructure)

- **核心框架**：Python + LangChain + LangGraph（编排）+ FastAPI（服务化）。
- **模型基座**：SiliconFlow (Qwen 7B) 用于推理与生成；BGE-M3 用于向量化与重排序。
- **数据存储**：Milvus 存储文本向量索引；

### 2. 数据层：高精度索引链路 (Data Layer)

- **多模态清洗**：利用 **MinerU** 工具解析研报 PDF，提取 Markdown 格式以保留文档结构。
- **元数据增强**：配合 **TokenTextSplitter** 进行语义切片，并利用 LLM 自动抽取 Topic 与 Keywords 写入 Metadata，增强过滤维度。

### 3. 感知层：查询理解 (Perception Layer)

- **上下文回溯**：针对口语化提问，利用 LLM 回溯历史对话，解决代词（如“它”）指代不明问题。
- **查询重写**：基于金融知识库校准语义，将用户模糊查询转化为精准的检索关键词。

### 4. 检索层：混合检索引擎 (Retrieval Layer)

- **双路召回**：并行执行 **Milvus 向量检索** 与基于“文档+知识路径”的 **BM25 稀疏检索**。
- **融合重排**：引入 **RRF 算法**合并结果，利用 **bge-reranker-v2-m3** 模型进行二次语义打分，锁定 Top-K 高信度上下文。

### 5. 决策与执行层：多 Agent 协作编排 (Decision & Execution Layer)

本层基于 **LangGraph** 构建，包含意图路由与四大核心子任务 Agent 的协作流。系统根据任务类型动态选择策略：简单任务走 **CoT 直接推理**，需行动任务走 **ReAct 思考-执行循环**，时延平均降低 40%。

- **意图分发 (Router)**：基于意图识别将请求精准路由至以下四大链路：
    1. **普通金融问答 Agent**：
        - *功能*：处理事实性金融问题。
        - *实现*：直接调用上述检索层的“混合检索+重排序”链路，结合 Milvus 知识库生成可信答案。
    2. **多模态 PDF 研报解析 Agent**：
        - *功能*：处理长文档阅读与摘要。
        - *实现*：调用 MinerU 解析工具与语义切片工具，对非结构化文档进行深度理解与问答。
    3. **深度投研报告生成 Agent**：
        - *功能*：撰写长篇时效性分析报告。
        - *实现*：通过 CoT（思维链）分解任务，调用联网搜索工具获取最新行情与新闻，弥补静态知识库的时效性不足。
    4. **智能图像/图表处理 Agent**：
        - *功能*：提取财报截图或图表数据。
        - *实现*：通过 Function Calling 自动调度 OCR 工具，将视觉信息转化为结构化数据供模型推理。

### 6. 生成与风控层：自我反思闭环 (Generation & Control Layer)

- **Self-Reflective Agent**：作为最终输出的把关者。
- **Self-Critique 机制**：在输出前校验金融逻辑与合规性。
- **闭环修正**：若置信度不足，自主触发 ToolCall (Web/MinerU) 获取补充证据并重写答案，形成“生成-反思-修正”闭环，显著抑制幻觉。
### 第一阶段（Sprint 1）：核心跑通 —— "最小化 RAG 问答闭环"

**目标**：实现“上传文档 -> 存入库 -> 提问 -> 回答”的最简全链路。不追求完美精度，只追求链路打通。

1. **环境与基座接入**：
    - 配置 Python 环境，安装 LangChain、Milvus SDK。
    - 接入 **SiliconFlow (Qwen 7B)** API，确保能进行基础对话。
    - 部署 **Milvus** (Docker/Lite版)，调通向量的增删改查。
2. **基础数据处理**：
    - 先暂时使用基础 PDF Loader，或者直接集成 **MinerU**（如果已就绪）将 PDF 转 Markdown。
    - 使用 **TokenTextSplitter** 进行切片。
    - 调用 Embedding 模型（BGE-M3）将文本向量化并存入 Milvus。
3. **朴素 RAG 对话**：
    - 写一个简单的 Python 脚本：接收用户 Query -> Milvus 检索 Top-3 -> 拼接 Prompt -> Qwen 生成回答。
    - *产出：一个简陋但能用的金融问答脚本。*

---

### 第二阶段（Sprint 2）：精度升级 —— "混合检索与重排"

**目标**：解决“查不准”的问题。在第一阶段基础上，升级检索引擎，这是金融场景的生命线。

1. **引入 BM25 稀疏检索**：
    - 为文档建立倒排索引，实现关键词匹配检索。
2. **实现双路融合 (RRF)**：
    - 编写 **RRF (Reciprocal Rank Fusion)** 函数，将 Milvus（语义结果）和 BM25（关键词结果）的排名进行加权合并。
3. **接入 Rerank 模型**：
    - 在融合结果的基础上，接入 **bge-reranker-v2-m3**。
    - 对 Top-N 个候选段落进行精细打分，只取 Top-K 给大模型。
    - *产出：一个高精度的金融检索 API。*

---

### 第三阶段（Sprint 3）：输入优化 —— "听懂人话"

**目标**：优化交互体验，解决用户“乱问”的问题。

1. **历史回溯 (Contextualizing)**：
    - 利用 Qwen 处理多轮对话，将“它的营收是多少？”改写为“贵州茅台2024年的营收是多少？”。
2. **查询重写 (Query Rewriting)**：
    - 引入 prompt 模板，让 LLM 将用户口语转化为金融专业检索词（如将“赚钱能力”转化为“净资产收益率/ROE”）。
    - *产出：具备上下文理解能力的增强型对话接口。*

---

### 第四阶段（Sprint 4）：架构重构 —— "LangGraph 多智能体编排"

**目标**：从“线性流程”转变为“网状流程”，接入多种工具。

1. **定义 Router (路由层)**：
    - 利用 Qwen 进行意图分类：是问答、读研报、写报告还是看图？。
2. **封装 Tool 节点**：
    - 将 **OCR 工具** 封装为 Tool Node（对应图像处理链路）。
    - 将 **联网搜索 API** 封装为 Tool Node（对应深度投研链路）。
3. **构建 Graph**：
    - 使用 **LangGraph** 将 Router、Retrieval、Tools 连接起来。
    - 实现简单的 **CoT**（针对简单任务）和 **ReAct**（针对复杂任务）的分支逻辑。
    - *产出：一个初具雏形的 Agent 智能体平台。*

---

### 第五阶段（Sprint 5）：质量闭环 —— "自我反思与修正"

**目标**：让 AI 学会“自我纠错”，达到上线标准。

1. **开发 Self-Critique 节点**：
    - 编写 Prompt，要求模型检查生成的答案：数据是否来源于上下文？逻辑是否通顺？有无合规风险？。
2. **构建修正回路 (Conditional Edges)**：
    - 在 LangGraph 中定义条件边：
        - 如果评分 Pass -> 结束。
        - 如果评分 Fail -> 跳转回 ToolCall（联网或重新检索）-> 重新生成。
    - *产出：具备高可靠性、低幻觉的最终版 FinSight AI。*