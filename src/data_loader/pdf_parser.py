"""
PDF è§£æå™¨ - ä½¿ç”¨ MinerUï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒè¡¨æ ¼å’Œå›¾ç‰‡ï¼‰
"""
import subprocess
from pathlib import Path
from typing import Optional, Dict
import logging

logger = logging.getLogger(__name__)


class PDFParser:
    """ä½¿ç”¨ MinerU è§£æ PDF ä¸º Markdownï¼ˆæ”¯æŒè¡¨æ ¼å’Œå›¾ç‰‡ï¼‰"""
    
    def __init__(
        self, 
        output_dir: str = "./data/processed",
        extract_images: bool = True,
        parse_method: str = "auto"  # auto, ocr, txt
    ):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.extract_images = extract_images
        self.parse_method = parse_method
    
    def parse(
        self, 
        pdf_path: str, 
        timeout: int = 300,
        lang: str = "ch"  # æ”¯æŒè¯­è¨€æŒ‡å®š
    ) -> Optional[Dict[str, str]]:
        """
        è§£æå•ä¸ª PDF
        
        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            lang: è¯­è¨€ä»£ç ï¼ˆch=ä¸­æ–‡, en=è‹±æ–‡ï¼‰
            
        Returns:
            {
                'markdown': Markdownæ–‡ä»¶è·¯å¾„,
                'images': å›¾ç‰‡ç›®å½•è·¯å¾„,
                'content_json': å†…å®¹JSONè·¯å¾„
            }
        """
        try:
            # MinerU å‘½ä»¤ï¼ˆæ–°ç‰ˆå‘½ä»¤åæ˜¯ mineruï¼‰
            cmd = [
                "mineru",  # æˆ– "magic-pdf" (æ—§ç‰ˆ)
                "-p", pdf_path,
                "-o", str(self.output_dir),
                "-m", self.parse_method,  # autoä¼šè‡ªåŠ¨è¯†åˆ«è¡¨æ ¼å’Œå›¾ç‰‡
                "--device", "cpu"  # å¼ºåˆ¶ä½¿ç”¨ CPUï¼Œé¿å… GPU æ˜¾å­˜ä¸è¶³
            ]
            
            # æ·»åŠ è¯­è¨€å‚æ•°ï¼ˆæå‡ä¸­æ–‡è¯†åˆ«ç‡ï¼‰
            if lang:
                cmd.extend(["--lang", lang])
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            if result.returncode == 0:
                # MinerU è¾“å‡ºç»“æ„:
                # output_dir/
                #   â””â”€â”€ pdf_name/
                #       â””â”€â”€ auto/                # MinerU ä¼šåˆ›å»ºè¿™ä¸ªå­ç›®å½•
                #           â”œâ”€â”€ pdf_name.md
                #           â”œâ”€â”€ pdf_name_content_list.json
                #           â”œâ”€â”€ pdf_name_model.json
                #           â””â”€â”€ images/
                
                pdf_name = Path(pdf_path).stem
                result_base = self.output_dir / pdf_name
                
                # é€’å½’æŸ¥æ‰¾ Markdown æ–‡ä»¶ï¼ˆé€‚é… MinerU çš„å®é™…è¾“å‡ºç»“æ„ï¼‰
                # ä½¿ç”¨ *.md è€Œä¸æ˜¯ç²¾ç¡®åŒ¹é…ï¼Œå› ä¸ºæ–‡ä»¶åå¯èƒ½è¢«æˆªæ–­
                md_files = list(result_base.rglob("*.md"))
                
                if md_files:
                    md_path = md_files[0]
                    result_dir = md_path.parent
                    images_dir = result_dir / "images"
                    content_json = result_dir / f"{pdf_name}_content_list.json"
                    
                    logger.info(f"âœ… è§£ææˆåŠŸ: {pdf_path}")
                    logger.info(f"   ğŸ“„ Markdown: {md_path}")
                    
                    if images_dir.exists():
                        image_count = len(list(images_dir.glob("*")))
                        logger.info(f"   ğŸ–¼ï¸  æå–å›¾ç‰‡: {image_count} å¼ ")
                    
                    return {
                        'markdown': str(md_path),
                        'images': str(images_dir) if images_dir.exists() else None,
                        'content_json': str(content_json) if content_json.exists() else None
                    }
                else:
                    logger.warning(f"âš ï¸  è§£æå¤±è´¥: {pdf_path}")
                    logger.warning(f"   æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶ï¼Œå¯èƒ½PDFå†…å®¹ä¸ºç©ºæˆ–æ ¼å¼ä¸æ”¯æŒ")
                    return None
                    
            logger.warning(f"âš ï¸  è§£æå¤±è´¥: {pdf_path}")
            logger.warning(f"   é”™è¯¯ä¿¡æ¯: {result.stderr[:200]}")
            return None
            
        except subprocess.TimeoutExpired:
            logger.error(f"âŒ è¶…æ—¶: {pdf_path}")
            return None
        except Exception as e:
            logger.error(f"âŒ å¼‚å¸¸: {pdf_path} - {e}")
            return None
    
    def batch_parse(self, pdf_dir: str, skip_existing: bool = True) -> list[Dict[str, str]]:
        """
        æ‰¹é‡è§£æï¼Œè¿”å›æ‰€æœ‰æˆåŠŸè§£æçš„ç»“æœ
        
        Args:
            pdf_dir: PDF æ–‡ä»¶ç›®å½•
            skip_existing: æ˜¯å¦è·³è¿‡å·²è§£æçš„æ–‡ä»¶ï¼ˆé»˜è®¤ Trueï¼‰
        """
        pdf_files = list(Path(pdf_dir).glob("*.pdf"))
        logger.info(f"ğŸ“š æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        
        parsed_results = []
        skipped_count = 0
        
        for pdf_path in pdf_files:
            pdf_name = pdf_path.stem
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»è§£æè¿‡
            if skip_existing:
                # æ£€æŸ¥è¾“å‡ºç›®å½•ä¸­æ˜¯å¦å­˜åœ¨å¯¹åº”çš„ markdown æ–‡ä»¶
                expected_md = self.output_dir / pdf_name / "auto" / f"{pdf_name}.md"
                if expected_md.exists():
                    logger.info(f"â­ï¸  è·³è¿‡å·²è§£æ: {pdf_path.name}")
                    # è¿”å›å·²å­˜åœ¨çš„ç»“æœ
                    result_dir = expected_md.parent
                    images_dir = result_dir / "images"
                    content_json = result_dir / f"{pdf_name}_content_list.json"
                    
                    parsed_results.append({
                        'markdown': str(expected_md),
                        'images': str(images_dir) if images_dir.exists() else None,
                        'content_json': str(content_json) if content_json.exists() else None
                    })
                    skipped_count += 1
                    continue
            
            # è§£ææ–°æ–‡ä»¶
            result = self.parse(str(pdf_path))
            if result:
                parsed_results.append(result)
        
        logger.info(f"\nâœ… å¤„ç†å®Œæˆ:")
        logger.info(f"   - è·³è¿‡å·²è§£æ: {skipped_count} ä¸ª")
        logger.info(f"   - æ–°è§£æ: {len(parsed_results) - skipped_count} ä¸ª")
        logger.info(f"   - æ€»è®¡: {len(parsed_results)}/{len(pdf_files)} ä¸ª")
        
        total_images = sum(
            len(list(Path(r['images']).glob("*"))) 
            for r in parsed_results 
            if r.get('images') and Path(r['images']).exists()
        )
        logger.info(f"   - æå–å›¾ç‰‡: {total_images} å¼ ")
        
        return parsed_results